
<!doctype html>
<html>

  <head>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <!--     Get up-to-date fontawesome config -->
    <script src="https://use.fontawesome.com/115eb0f096.js"></script>
    <script>
     	function showhide(id) {
    	var e = document.getElementById(id);
    	e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 		}
    </script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Yuchen Zeng's Homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <!--     For academic icon such as google scholar -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="icon" type="image/x-icon" href="favicon.ico?">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,500,600,700" rel="stylesheet">
    
    <!--if lt IE 9>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <!endif-->
   
    
  </head>

  <body>
    <div class="wrapper">
      <header>

        <img border=0 Vspace=5 Hspace=0
        src="images/me.JPG"
        alt="Zeng"
        width="221" height="294.7">
        <br><br>

        <p>
          <par><font size=3px>Yuchen Zeng (曾语晨)</font></par><br>
          PhD Candidate<br>
          University of Wisconsin-Madison<br>
          <code>yzeng58 @ wisc . edu</code>
        </p>

<!--         <a href=https://github.com/Leiay/>Github</a> |  -->
<!--         <a href=https://scholar.google.com/citations?user=ul5MsOIAAAAJ&hl=en>Google Scholar</a> | -->
<!--         <a href=https://www.linkedin.com/in/liu-y-aa355517a>LinkedIn</a><br> -->
        <pre><a href="https://github.com/yzeng58" class="fa fa-github fa-2x"></a> <a href="https://scholar.google.com/citations?hl=en&user=vex4iuYAAAAJ"><i class="ai ai-google-scholar fa-2x"></i></a> <a href="https://www.linkedin.com/in/yuchen-zeng-46921619a/" class="fa fa-linkedin fa-2x"></a> <a href="https://twitter.com/yzeng58" class="fa fa-twitter fa-2x"></a></pre>
      </header>

      <section>
      <h1>About Me</h1>
        
      I am a graduate student pursuing a PhD's degree in the Department of Computer Science at the <a href="https://www.wisc.edu/">University of Wisconsin-Madison</a>. 
      I am advised by Prof. <a href="http://kangwooklee.com/index.html">Kangwook Lee</a>. 
      My current research interests include both large language models (LLMs).
      I received my Master's degree in Statistics from UW-Madison in 2020, where I was advised by Prof.  <a href="https://pages.stat.wisc.edu/~miaoyan/">Miaoyan Wang</a>. 
      Before joining UW-Madison, I completed my Bachelor's degree in Statistics from the School of Mathematical Sciences at <a href="http://en.math.nankai.edu.cn/">Nankai University</a> in 2019.
      <br><br>


      <h2 id="Pubs">Publications</h2>    

      <h3> Deep Learning with Foundation Models </h3>

      Humor-Aware AI: Evaluating and Improving LLMs in Meme Analysis <br>
      <b>Yuchen Zeng</b>, Hemang Rajvanshy, Wonjun Kang, Jifan Zhang, Bob Mankoff, Kangwook Lee, Yixin Nie, Yipin Zhou<br>
      <i>Under Review</i><br>
      <a href="https://github.com/yzeng58/memeSage">[Code]</a>
      <br><br>

        DARWIN 1.5: Large Language Models as Materials Science Adapted Learners <br>
        Tong Xie*, Yuwei Wan*, Yixuan Liu, <b>Yuchen Zeng</b>, Wenjie Zhang, Chunyu Kit, Dongzhan Zhou, Bram Hoexter<br>
        <i>Under Review</i><br>
        <a href="https://arxiv.org/abs/2412.11970">[Paper]</a>
        <a href="https://github.com/MasterAI-EAM/Darwin">[Code]</a>
        <br><br>

        TabFlex: Scaling Tabular Learning to Millions with Linear Attention <br>
        <b>Yuchen Zeng*</b>, Tuan Dinh*, Wonjun Kang, Andreas Mueller<br>
        <i>International Conference on Machine Learning 2025</i> (<b>ICML</b>) Spotlight (Top 2.6%)<br>
        <a href="https://openreview.net/forum?id=f8aganC0tN">[Paper]</a>
        <a href="https://github.com/microsoft/ticl/tree/develop">[Code]</a>
        <br><br>

        Parameter-Efficient Fine-Tuning of State Space Models <br>
        Kevin Galim*, Wonjun Kang*, <b>Yuchen Zeng</b>*, Hyung Il Koo, Kangwook Lee<br>
        <i>International Conference on Machine Learning 2025</i> (<b>ICML</b>)<br>
        <a href="https://arxiv.org/abs/2410.09016">[Paper]</a>
        <a href="https://github.com/furiosa-ai/ssm-peft">[Code]</a>
        <a href="https://x.com/yzeng58/status/1846237275648147771">[Summary]</a> 
        <br><br>

        Can MLLMs Perform Text-to-Image In-Context Learning? <br>
        <b>Yuchen Zeng</b>*, Wonjun Kang*, Yicong Chen, Hyung Il Koo, Kangwook Lee<br>
        <i>2024 Conference on Language Modeling</i> (<b>COLM</b>)<br>
        <a href="https://arxiv.org/abs/2402.01293">[Paper]</a> 
        <a href="https://github.com/UW-Madison-Lee-Lab/CoBSAT">[Code]</a>
        <a href="https://twitter.com/yzeng58/status/1758679354408829250">[Summary]</a> 
        <a href="https://www.youtube.com/watch?v=GNLkneJWnEE">[45-Minute Talk]</a> 
        <br><br>

        The Expressive Power of Low-Rank Adaptation <br>
        <b>Yuchen Zeng</b>, Kangwook Lee<br>
        <i>2024 International Conference on Learning Representation</i> (<b>ICLR</b>)<br>
        <a href="https://arxiv.org/abs/2310.17513">[Paper]</a> 
        <a href="https://github.com/UW-Madison-Lee-Lab/Expressive_Power_of_LoRA">[Code]</a>
        <a href="https://twitter.com/yzeng58/status/1717982497592516727">[Summary]</a> 
        <a href="https://www.bilibili.com/video/BV14G411y7yh/?spm_id_from=333.337.search-card.all.click&vd_source=84cfc6ef888583c3507782aa1d2158d9">[45-Minute Talk in Chinese]</a> <br> 
        <br>

        Coded Prompts for Large Language Models<br>
        Ziqian Lin, Yicong Chen, <b>Yuchen Zeng</b>, Kangwook Lee<br>
        <i>Neural Information Processing Systems 2023</i> (<b>NeurIPS</b>) R0-FoMo Workshop<br>
        <a href="https://openreview.net/pdf?id=EztQmfnMLg">[Paper]</a>
        <a href="https://github.com/UW-Madison-Lee-Lab/Coded_Prompts_for_LLMs">[Code]</a> 
        <br><br>
        

        LIFT: Language-Interfaced FineTuning for Non-Language Machine Learning Tasks<br>
        Tuan Dinh*, <b>Yuchen Zeng*</b>, Ruisu Zhang, Ziqian Lin, Michael Gira, Shashank Rajput, Jy-yong Sohn, Dimitris Papailiopoulos, Kangwook Lee<br>
        <i>Neural Information Processing Systems 2022</i> (<b>NeurIPS</b>)<br>
        <a href="https://arxiv.org/abs/2206.06565">[Paper]</a> 
        <a href="https://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning">[Code]</a> 
        <a href="https://x.com/Kangwook_Lee/status/1536789544820957184?s=20">[Summary]</a> 
        <a href="https://nips.cc/virtual/2022/poster/54500">[5-Minute Video]</a> 
        <a href="https://uw-madison-lee-lab.github.io/LanguageInterfacedFineTuning/">[Website]</a> 
        <a href="https://www.bilibili.com/video/BV1zV4y187za/?spm_id_from=333.788.recommend_more_video.0&vd_source=84cfc6ef888583c3507782aa1d2158d9">[45-Minute Talk in Chinese]</a>
        <br> 

      <h3>Machine Learning Fairness</h3>
        Federated Learning with Local Fairness Constraints<br>
        <b>Yuchen Zeng</b>, Hongxu Chen, Kangwook Lee<br>
        <i>2023 IEEE International Symposium on Information Theory</i> (<b>ISIT</b>)<br>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10206590">[Paper]</a> 
        <br><br>

        Equal Improvability: A New Fairness Notion Considering the Long-Term Impact<br>
        Ozgur Guldogan*, <b>Yuchen Zeng</b>*, Jy-yong Sohn, Ramtin Pedarsani, Kangwook Lee<br>
        <i>2023 International Conference on Learning Representation</i> (<b>ICLR</b>)<br>
        <a href="https://arxiv.org/abs/2210.06732">[Paper]</a> 
        <a href="https://github.com/guldoganozgur/ei_fairness">[Code]</a>
        <a href="https://x.com/Kangwook_Lee/status/1652907520518934528?s=20">[Summary]</a> 
        <a href="https://iclr.cc/virtual/2023/poster/10869">[5-Minute Video]</a> 
        <a href="https://montrealethics.ai/equal-improvability-a-new-fairness-notion-considering-the-long-term-impact/">[Article]</a>
        <br><br>

        Outlier-Robust Group Inference via Gradient Space Clustering<br>
        <b>Yuchen Zeng</b>, Kristjan Greenewald, Kangwook Lee, Justin Solomon, Mikhail Yurochkin<br>
        <!-- <i>Neural Information Processing Systems 2023</i> (<b>NeurIPS</b>) Distribution Shifts Workshop<br> -->
        Preprint<br>
        <a href="https://arxiv.org/abs/2210.06759">[Paper]</a> <a href="https://github.com/yzeng58/private_demographics">[Code]</a><br><br>

        Improving fairness via federated learning<br>
        <b>Yuchen Zeng</b>, Hongxu Chen, Kangwook Lee<br>
        <!-- <i>Association for the Adavancement of Artificial Intelligence 2022</i> (<b>AAAI</b>) FL-AAAI Workshop<br>
        <i>Machine Learning and Systems 2022</i> (<b>MLSys</b>) Cross-FL Workshop <br> -->
        Preprint<br>
        <a href="https://arxiv.org/abs/2110.15545">[Paper]</a> 
        <a href="https://github.com/UW-Madison-Lee-Lab/Improving-Fairness-via-Federated-Learning">[Code]</a> 
        <a href="https://x.com/Kangwook_Lee/status/1455624858050641926?s=20">[Summary]</a>

        
        <h3>Tensor Learning</h3>
        Multiway clustering via tensor block models<br>
        Miaoyan Wang, <b>Yuchen Zeng</b><br>
        <i>Neural Information Processing Systems 2019</i> (<b>NeurIPS</b>)<br>
        <a href="https://arxiv.org/abs/1906.03807">[Paper]</a> 
        <a href="https://cran.r-project.org/web/packages/tensorsparse/index.html">[Code]</a>
        <a href="https://www.youtube.com/watch?v=b3sOTLwxHMY">[3-Minute Video]</a>

        <h2 id="Pubs">Services and Leadership</h2>
        Recipient of 2024 COLM DEI Travel Scholarship <br>
        Selected to participate in <a href="https://midas.umich.edu/future-leaders-summit-2024/">Future Leaders Summit</a><br>
        Organizer of <a href="https://mlopt.ece.wisc.edu/idea-seminar/">MLOPT Idea Seminar</a><br>
        Conference reviewer: NeurIPS, ICML, ICLR, TMLR, AISTATS

        <h2 id="Pubs">Work Experience</h2>
        <a href="https://about.meta.com/">Meta</a>, Fall 2024 <br>
        Mentored by Dr. <a href="https://yipin.github.io/">Yipin Zhou</a> and Dr. <a href="https://easonnie.github.io/">Yixin Nie</a> <br><br>
        <a href="https://www.microsoft.com/en-us/">Microsoft</a>, Summer 2024 <br>
        Mentored by Dr. <a href="https://amueller.github.io/">Andreas Christian Müller</a> <br><br>
        <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>, Summer 2022 <br>
        Mentored by Dr. <a href="https://moonfolk.github.io/">Mikhail Yurochkin</a> and Prof. <a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a>

      </tbody></table>

      </section>

      <footer>
          <p><span style="font-size:0.7em">Based on <a href="https://github.com/orderedlist/minimal" style="color:black">minimal</a> by <a href="https://github.com/orderedlist" style="color:black">orderedlist</a>&mdash;<a href="http://creativecommons.org/licenses/by-sa/3.0/" style="color:black">CC BY-SA 3.0</a></span></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>

 </html>

